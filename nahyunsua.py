import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path

from sklearn.preprocessing import LabelEncoder
from xgboost import XGBRegressor

# ------------------------------------------------------------
# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# ------------------------------------------------------------

@st.cache_data
def load_data():
    base_dir = Path(__file__).resolve().parent
    hist_path = base_dir / "green_en.csv"   # ê³¼ê±° ë°ì´í„° (ì˜ì–´ ì»¬ëŸ¼)

    df = pd.read_csv(hist_path, encoding="utf-8-sig")

    # ì»¬ëŸ¼ ì •ë¦¬ (í˜¹ì‹œ ëª¨ë¥¼ ê³µë°± ì œê±°)
    df.columns = df.columns.astype(str).str.strip()

    # year ì •ìˆ˜í˜•
    df["year"] = df["year"].astype(int)

    return df


# ------------------------------------------------------------
# 2. XGBoost í•™ìŠµ + 2050ë…„ê¹Œì§€ ì˜ˆì¸¡
# ------------------------------------------------------------

@st.cache_data
def train_and_forecast(df: pd.DataFrame, year_until: int = 2050):
    """
    df: green_en.csv ë¡œë¶€í„° ì½ì€ ì›ë³¸ ë°ì´í„°
        columns: ['region', 'year', 'emissions', 'area', 'emissions_per_area']
    """

    # (1) ì§€ì—­ ë¼ë²¨ ì¸ì½”ë”©
    le_region = LabelEncoder()
    df["region_code"] = le_region.fit_transform(df["region"])

    # (2) ì—°ë„ë³„ í‰ê· (ë…¸ì´ì¦ˆ ì¤„ì´ê¸°) â€“ ì§€ì—­/ì—°ë„ ë‹¨ìœ„ë¡œ í‰ê·  ë©´ì ë‹¹ ë°°ì¶œëŸ‰ ì‚¬ìš©
    grouped = (
        df.groupby(["region", "region_code", "year"], as_index=False)
        .agg({"emissions_per_area": "mean"})
    )

    # í•™ìŠµ ë°ì´í„°
    X = grouped[["year", "region_code"]]
    y = grouped["emissions_per_area"]

    # (3) XGBoost íšŒê·€ ëª¨ë¸
    model = XGBRegressor(
        n_estimators=300,
        learning_rate=0.05,
        max_depth=4,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
    )
    model.fit(X, y)

    # (4) ë¯¸ë˜ ì—°ë„(í˜„ì¬ ë°ì´í„°ì˜ ë§ˆì§€ë§‰ ì—°ë„+1 ~ 2050) ìƒì„±
    max_hist_year = grouped["year"].max()
    future_years = list(range(max_hist_year + 1, year_until + 1))

    regions = grouped[["region", "region_code"]].drop_duplicates()

    future_rows = []
    for _, row in regions.iterrows():
        r_name = row["region"]
        r_code = row["region_code"]
        for yr in future_years:
            future_rows.append(
                {"region": r_name, "region_code": r_code, "year": yr}
            )

    future_df = pd.DataFrame(future_rows)

    # (5) ì˜ˆì¸¡
    X_future = future_df[["year", "region_code"]]
    future_df["pred_emissions_per_area"] = model.predict(X_future)

    # (6) ê³¼ê±° + ì˜ˆì¸¡ í•©ì¹˜ê¸° (ì‹œê°í™”ìš©)
    hist_for_plot = grouped.rename(
        columns={"emissions_per_area": "value"}
    )
    hist_for_plot["type"] = "historical"

    fut_for_plot = future_df.rename(
        columns={"pred_emissions_per_area": "value"}
    )
    fut_for_plot["type"] = "forecast"

    full = pd.concat(
        [hist_for_plot, fut_for_plot],
        ignore_index=True
    )

    return full, grouped, future_df


# ------------------------------------------------------------
# 3. Streamlit UI
# ------------------------------------------------------------

st.set_page_config(page_title="XGBoost 2050 Forecast", layout="wide")
st.title("XGBoost ê¸°ë°˜ 2050ë…„ ë©´ì ë‹¹ ë°°ì¶œëŸ‰ ì˜ˆì¸¡ ëŒ€ì‹œë³´ë“œ")

st.write("""
ì´ ëŒ€ì‹œë³´ë“œëŠ” **green_en.csv**(ê³¼ê±° ë°ì´í„°)ë¥¼ ì‚¬ìš©í•´  
XGBoost íšŒê·€ ëª¨ë¸ë¡œ 2050ë…„ê¹Œì§€ì˜ **emissions_per_area**(ë©´ì ë‹¹ ë°°ì¶œëŸ‰)ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.

- ì™¼ìª½ì—ì„œ ì§€ì—­ì„ ì„ íƒí•˜ë©´  
  â†’ ê³¼ê±° + 2050ë…„ê¹Œì§€ì˜ ì˜ˆì¸¡ ì¶”ì„¸ ê·¸ë˜í”„ê°€ ë‚˜ì˜¤ê³   
  â†’ ì•„ë˜ì—ëŠ” í•´ë‹¹ ì§€ì—­ì˜ ë°ì´í„° í…Œì´ë¸”ì´ í•¨ê»˜ í‘œì‹œë©ë‹ˆë‹¤.
""")

# ë°ì´í„° & ëª¨ë¸
df_hist = load_data()
full, grouped_hist, future_pred = train_and_forecast(df_hist, year_until=2050)

regions = sorted(full["region"].unique())
selected_region = st.sidebar.selectbox("ì§€ì—­ ì„ íƒ (region)", regions)

tab1, tab2 = st.tabs(["ì¶”ì„¸ ê·¸ë˜í”„ (Trend)", "ë°ì´í„° í…Œì´ë¸” (Table)"])

# ------------------------------------------------------------
# 4. ì¶”ì„¸ ê·¸ë˜í”„
# ------------------------------------------------------------
with tab1:
    st.subheader(f"{selected_region} â€” Historical vs Forecast (to 2050)")

    region_data = full[full["region"] == selected_region].copy()
    region_data = region_data.sort_values("year")

    # Streamlit line_chartë¥¼ ì“°ê¸° ìœ„í•´ í”¼ë²— í˜•íƒœë¡œ ë³€í™˜
    # index = year, columns = type, values = value
    pivot = (
        region_data.pivot(index="year", columns="type", values="value")
        .sort_index()
    )

    st.line_chart(pivot)

    st.caption("â€¢ historical: ì‹¤ì œ ê³¼ê±° ë°ì´í„° í‰ê·  (ì—°ë„ë³„)\n"
               "â€¢ forecast: XGBoostë¡œ ì˜ˆì¸¡í•œ ê°’")


# ------------------------------------------------------------
# 5. ë°ì´í„° í…Œì´ë¸”
# ------------------------------------------------------------
with tab2:
    st.subheader(f"{selected_region} â€” ë°ì´í„° ìƒì„¸ (historical + forecast)")

    region_hist = grouped_hist[grouped_hist["region"] == selected_region].copy()
    region_fut = future_pred[future_pred["region"] == selected_region].copy()

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**Historical (ê³¼ê±°)**")
        st.dataframe(
            region_hist[["region", "year", "emissions_per_area"]],
            use_container_width=True,
        )

    with col2:
        st.markdown("**Forecast (ì˜ˆì¸¡)**")
        st.dataframe(
            region_fut[["region", "year", "pred_emissions_per_area"]],
            use_container_width=True,
        )

    st.markdown("### ì „ì²´ ì˜ˆì¸¡ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ")

    # ì „ì²´ ì˜ˆì¸¡ CSV (ëª¨ë“  ì§€ì—­, ëª¨ë“  ì—°ë„)
    full_export = full.copy()
    full_export = full_export.sort_values(["region", "year", "type"])

    csv_bytes = full_export.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        label="ğŸ“¥ ì „ì²´ ì˜ˆì¸¡ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ",
        data=csv_bytes,
        file_name="xgboost_forecast_full.csv",
        mime="text/csv",
    )
