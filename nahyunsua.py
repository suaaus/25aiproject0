import streamlit as st
import pandas as pd
import numpy as np
from pathlib import Path

import folium
from folium import CircleMarker
from branca.colormap import LinearColormap
from streamlit_folium import st_folium

from xgboost import XGBRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error


# ===========================
# 0. ê¸°ë³¸ ì„¤ì •
# ===========================
st.set_page_config(
    page_title="ëŒ€í•œë¯¼êµ­ ë„ì‹œë³„ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ ì˜ˆì¸¡ ëª¨ë¸",
    layout="wide"
)

st.title("ëŒ€í•œë¯¼êµ­ ë„ì‹œë³„ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ ì˜ˆì¸¡ ëª¨ë¸")


# ===========================
# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (+ ì „ì²˜ë¦¬: ì§€ì—­Ã—ì—°ë„ í‰ê· )
# ===========================
@st.cache_data
def load_data():
    base_dir = Path(__file__).resolve().parent
    hist_path = base_dir / "green_en.csv"          # ê³¼ê±° ë°ì´í„°
    coord_path = base_dir / "XGBoostData_en.csv"   # ì§€ì—­ë³„ ìœ„ë„/ê²½ë„

    df_hist = pd.read_csv(hist_path, encoding="utf-8-sig")
    df_coord = pd.read_csv(coord_path, encoding="utf-8-sig")

    # ì»¬ëŸ¼ ì´ë¦„ ê³µë°± ì œê±°
    df_hist.columns = df_hist.columns.str.strip()
    df_coord.columns = df_coord.columns.str.strip()

    # íƒ€ì… ì •ë¦¬
    df_hist["region"] = df_hist["region"].astype(str)
    df_hist["year"] = pd.to_numeric(df_hist["year"], errors="coerce").astype("Int64")
    df_hist["emissions_per_area"] = pd.to_numeric(
        df_hist.get("emissions_per_area"), errors="coerce"
    )

    # ì“°ë ˆê¸° í–‰ ì œê±°
    df_hist = df_hist.dropna(subset=["region", "year", "emissions_per_area"])
    df_hist["year"] = df_hist["year"].astype(int)

    # ğŸ”¥ í•µì‹¬ ì „ì²˜ë¦¬: ì§€ì—­Ã—ì—°ë„ë³„ í‰ê· ìœ¼ë¡œ 1í–‰ì”©ë§Œ ë‚¨ê¸°ê¸°
    agg_dict = {"emissions_per_area": "mean"}
    if "emissions" in df_hist.columns:
        agg_dict["emissions"] = "mean"
    if "area" in df_hist.columns:
        agg_dict["area"] = "mean"

    df_hist_clean = (
        df_hist
        .groupby(["region", "year"], as_index=False)
        .agg(agg_dict)
    )

    # ì¢Œí‘œ íƒ€ì… ì •ë¦¬
    df_coord["region"] = df_coord["region"].astype(str)
    df_coord["lat"] = pd.to_numeric(df_coord["lat"], errors="coerce")
    df_coord["lon"] = pd.to_numeric(df_coord["lon"], errors="coerce")

    return df_hist_clean, df_coord


# ===========================
# 2. ì„ í˜•íšŒê·€ + XGBoost(ì”ì°¨) í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ + MAE
# ===========================
@st.cache_data
def train_and_forecast(df_hist: pd.DataFrame, year_until: int = 2050):
    """
    1) ê° ì§€ì—­ë³„ë¡œ (year â†’ emissions_per_area) ì„ í˜•íšŒê·€ë¡œ í° ì¶”ì„¸ ì¡ê¸°
    2) ê·¸ ì¶”ì„¸ì—ì„œ ë²—ì–´ë‚˜ëŠ” ì”ì°¨ë¥¼ XGBoostë¡œ í•™ìŠµ
    3) ìµœì¢… ì˜ˆì¸¡ = ì„ í˜•ì¶”ì„¸ + ì”ì°¨ì˜ˆì¸¡ (hybrid)
    4) ê³¼ê±° êµ¬ê°„ì—ì„œ hybridì™€ ì‹¤ì œ ê°’ì˜ MAE ê³„ì‚°
    """
    regions = sorted(df_hist["region"].unique())
    min_year = int(df_hist["year"].min())
    max_year = int(df_hist["year"].max())
    all_years = np.arange(min_year, year_until + 1)

    full_rows = []
    mae_rows = []

    for region in regions:
        g = df_hist[df_hist["region"] == region].sort_values("year").copy()
        years = g["year"].values.astype(np.float32)
        y = g["emissions_per_area"].values.astype(np.float32)

        X_hist = years.reshape(-1, 1)

        # 1) ì„ í˜• íšŒê·€ë¡œ í° ì¶”ì„¸
        lin = LinearRegression()
        lin.fit(X_hist, y)
        y_lin_hist = lin.predict(X_hist)
        resid_hist = y - y_lin_hist

        # 2) XGBoostë¡œ ì”ì°¨ í•™ìŠµ (ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ìƒëµ)
        use_xgb = len(g) >= 4
        if use_xgb:
            xgb = XGBRegressor(
                n_estimators=300,
                learning_rate=0.05,
                max_depth=3,
                subsample=0.9,
                colsample_bytree=0.8,
                objective="reg:squarederror",
                tree_method="hist",
                random_state=42,
            )
            xgb.fit(X_hist, resid_hist)
            resid_pred_hist = xgb.predict(X_hist)
        else:
            resid_pred_hist = np.zeros_like(resid_hist)

        # í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡(ê³¼ê±° êµ¬ê°„)
        y_hybrid_hist = y_lin_hist + resid_pred_hist

        # 3) ë¯¸ë˜ êµ¬ê°„ ì˜ˆì¸¡
        X_full = all_years.reshape(-1, 1).astype(np.float32)
        y_lin_full = lin.predict(X_full)

        if use_xgb:
            resid_full = xgb.predict(X_full)
        else:
            resid_full = np.zeros_like(y_lin_full)

        y_hybrid_full = y_lin_full + resid_full

        # MAE: ê³¼ê±° êµ¬ê°„ì—ì„œ ì‹¤ì œ vs hybrid
        mae = float(mean_absolute_error(y, y_hybrid_hist))
        mae_rows.append({"region": region, "MAE": mae})

        # full_rows êµ¬ì„± (ê³¼ê±° + ë¯¸ë˜)
        for yr, actual, pred in zip(years, y, y_hybrid_hist):
            full_rows.append(
                {
                    "region": region,
                    "year": int(yr),
                    "kind": "history",
                    "actual": float(actual),
                    "pred": float(pred),
                }
            )

        for yr, pred in zip(all_years, y_hybrid_full):
            # ë¯¸ë˜ êµ¬ê°„: actual ì—†ìŒ
            if yr in years:
                # ì´ë¯¸ ìœ„ì—ì„œ historyë¡œ ë„£ì—ˆìœ¼ë‹ˆ ìŠ¤í‚µ
                continue
            full_rows.append(
                {
                    "region": region,
                    "year": int(yr),
                    "kind": "forecast",
                    "actual": np.nan,
                    "pred": float(pred),
                }
            )

    df_full = pd.DataFrame(full_rows)
    df_mae = pd.DataFrame(mae_rows).sort_values("MAE")

    return df_full, df_mae


# ===========================
# 3. ì¶”ì„¸ ì„¤ëª… & í•´ê²°ë°©ì•ˆ í…ìŠ¤íŠ¸
# ===========================
def describe_trend_and_solution(df_full: pd.DataFrame, region: str) -> str:
    df_r = df_full[df_full["region"] == region].copy()
    df_r = df_r.sort_values("year")

    x = df_r["year"].values
    y = df_r["pred"].values
    coef = np.polyfit(x, y, 1)
    slope = coef[0]
    start_val = y[0]
    end_val = y[-1]

    if slope > 0:
        trend_text = f"â†’ {region}ì€(ëŠ”) 2050ë…„ê¹Œì§€ **ë©´ì ë‹¹ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ì´ ì¦ê°€í•˜ëŠ” ì¶”ì„¸**ì…ë‹ˆë‹¤."
    elif slope < 0:
        trend_text = f"â†’ {region}ì€(ëŠ”) 2050ë…„ê¹Œì§€ **ë©´ì ë‹¹ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ì´ ê°ì†Œí•˜ëŠ” ì¶”ì„¸**ì…ë‹ˆë‹¤."
    else:
        trend_text = f"â†’ {region}ì€(ëŠ”) 2050ë…„ê¹Œì§€ **í° ë³€í™”ê°€ ì—†ëŠ” ì •ì²´ ì¶”ì„¸**ë¥¼ ë³´ì…ë‹ˆë‹¤."

    change_ratio = (end_val - start_val) / max(start_val, 1e-6) * 100
    change_text = f"   Â· ì´ˆê¸° ì—°ë„ì™€ ë¹„êµí–ˆì„ ë•Œ, 2050ë…„ì—ëŠ” ì•½ **{change_ratio:.1f}%** ë³€í™”ê°€ ì˜ˆìƒë©ë‹ˆë‹¤."

    # ì „ì²´ forecast ê°’ ê¸°ì¤€ìœ¼ë¡œ ìƒÂ·í•˜ìœ„ êµ¬ê°„ ì •ì˜
    all_forecast = df_full[df_full["kind"] == "forecast"]["pred"].dropna()
    high_threshold = np.percentile(all_forecast, 75)
    low_threshold = np.percentile(all_forecast, 25)
    level = end_val

    if level >= high_threshold and slope > 0:
        level_text = (
            "   Â· ì˜ˆì¸¡ìƒ 2050ë…„ì—ë„ **ì „êµ­ ìƒìœ„ 25% ìˆ˜ì¤€ì˜ ë†’ì€ ë°°ì¶œ ë°€ë„**ë¥¼ ìœ ì§€í•˜ê³  ìˆì–´, "
            "ê°•ë ¥í•œ ê°ì¶• ì •ì±…ì´ í•„ìš”í•œ ì§€ì—­ì…ë‹ˆë‹¤."
        )
        solution_text = (
            "- ëŒ€í˜• ì‚°ì—…Â·ë°œì „ ì‹œì„¤ì˜ **ì—ë„ˆì§€ íš¨ìœ¨ ê°œì„  ë° ì—°ë£Œ ì „í™˜**(ì„íƒ„â†’ê°€ìŠ¤Â·ì¬ìƒì—ë„ˆì§€) ì¶”ì§„\n"
            "- ê±´ë¬¼Â·ìˆ˜ì†¡ ë¶€ë¬¸ì˜ **ì—ë„ˆì§€ íš¨ìœ¨ ë¦¬ëª¨ë¸ë§**ê³¼ ì „ê¸°ì°¨Â·ìˆ˜ì†Œì°¨ ë³´ê¸‰ í™•ëŒ€\n"
            "- ì§€ì—­ ë¶„ì‚°ì—ë„ˆì§€(íƒœì–‘ê´‘, í’ë ¥, ë°”ì´ì˜¤ê°€ìŠ¤ ë“±)ì™€ **ë§ˆì´í¬ë¡œê·¸ë¦¬ë“œ** êµ¬ì¶•ìœ¼ë¡œ "
            "ì „ë ¥ ìë¦½ë¥ ì„ ë†’ì´ëŠ” ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤.\n"
            "- ì§€ìì²´ ì°¨ì›ì—ì„œ **íƒ„ì†Œì¤‘ë¦½ì§€ì›ì„¼í„°**ì™€ ì—°ê³„í•œ ê°ì¶•ì‚¬ì—… ë°œêµ´, ì£¼ë¯¼ ì°¸ì—¬í˜• íƒœì–‘ê´‘ ë“± "
            "ì§€ì—­ ë§ì¶¤í˜• í”„ë¡œì íŠ¸ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤."
        )
    elif level <= low_threshold and slope < 0:
        level_text = (
            "   Â· 2050ë…„ì—ëŠ” **ì „êµ­ í•˜ìœ„ 25% ìˆ˜ì¤€ì˜ ë‚®ì€ ë°°ì¶œ ë°€ë„**ë¥¼ ë³´ì´ë©°, "
            "ê°ì¶•ì´ ë¹„êµì  ì˜ ì´ë¤„ì§€ê³  ìˆëŠ” ì§€ì—­ì…ë‹ˆë‹¤."
        )
        solution_text = (
            "- ì´ë¯¸ ì§„í–‰ ì¤‘ì¸ ê°ì¶•ì •ì±…(ì¬ìƒì—ë„ˆì§€ í™•ëŒ€, ê±´ë¬¼ íš¨ìœ¨í™” ë“±)ì„ ìœ ì§€í•˜ë©´ì„œ, "
            "ì§€ì—­ íŠ¹í™” ì‚°ì—…ê³¼ ì—°ê³„í•œ **ë…¹ìƒ‰ ì¼ìë¦¬ ì°½ì¶œ**ì— ì´ˆì ì„ ë‘˜ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
            "- ë†ì´ŒÂ·ì–´ì´Œ ì§€ì—­ì´ë¼ë©´ ë°”ì´ì˜¤ê°€ìŠ¤, ë†ì—… íê¸°ë¬¼ ì—ë„ˆì§€í™” ë“± "
            "**ì§€ì—­ ìì› ê¸°ë°˜ ë¶„ì‚°ì—ë„ˆì§€ ëª¨ë¸**ì„ ê°•í™”í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n"
            "- ì£¼ë¯¼ ì°¸ì—¬ í”„ë¡œê·¸ë¨ê³¼ ê¸°í›„ êµìœ¡Â·í™ë³´ë¥¼ í†µí•´ **ì§€ì—­ íƒ„ì†Œì¤‘ë¦½ ë¬¸í™”ë¥¼ ì •ì°©**ì‹œí‚¤ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤."
        )
    else:
        level_text = (
            "   Â· ë°°ì¶œ ë°€ë„ëŠ” ì „êµ­ í‰ê· ~ì¤‘ê°„ ìˆ˜ì¤€ì´ë©°, "
            "ì •ì±… ë°©í–¥ì— ë”°ë¼ í–¥í›„ ì¶”ì„¸ê°€ í¬ê²Œ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆëŠ” ì§€ì—­ì…ë‹ˆë‹¤."
        )
        solution_text = (
            "- ê±´ë¬¼Â·êµí†µÂ·ì‚°ì—… ë¶€ë¬¸ì˜ **ê¸°ë³¸ì ì¸ ì—ë„ˆì§€ íš¨ìœ¨ ê¸°ì¤€ ê°•í™”**ì™€ ì¹œí™˜ê²½ ì„¤ë¹„ ë„ì…ì„ ë³‘í–‰í•´ì•¼ í•©ë‹ˆë‹¤.\n"
            "- ê³µê³µê±´ë¬¼ ì§€ë¶• ë° ìœ íœ´ë¶€ì§€ë¥¼ í™œìš©í•œ **íƒœì–‘ê´‘Â·ì—°ë£Œì „ì§€ ì„¤ì¹˜** ë“±, "
            "ê³µìœ ë¶€ì§€ ì¬ìƒì—ë„ˆì§€ ì‚¬ì—…ì„ ì ê·¹ ê²€í† í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.\n"
            "- ê´‘ì—­ ì§€ìì²´ ë° ì¤‘ì•™ì •ë¶€ì˜ ê°ì¶•ëª©í‘œì™€ ì—°ê³„í•˜ì—¬, "
            "**ê¸°ì´ˆì§€ìì²´ ë‹¨ìœ„ì˜ ì‹¤ì²œí˜• ê°ì¶•ì‚¬ì—…(ê·¸ë¦°ë¦¬ëª¨ë¸ë§, ì¹œí™˜ê²½ êµí†µ ì¸í”„ë¼ ë“±)**ì„ ê¾¸ì¤€íˆ í™•ì¥í•´ì•¼ í•©ë‹ˆë‹¤."
        )

    text = "\n".join([
        trend_text,
        change_text,
        level_text,
        "",
        "ğŸ“Œ **ì •ì±…Â·í•´ê²° ë°©ì•ˆ ì œì•ˆ**",
        solution_text
    ])
    return text


# ===========================
# 4. ì§€ë„ ìƒì„± í•¨ìˆ˜ (íŒŒë‘~ë¹¨ê°•, Top5 ê°•ì¡°)
# ===========================
def create_map(df_full, df_coord, selected_year, top5_year=2050):
    """
    ì„ íƒ ì—°ë„ ê¸°ì¤€ìœ¼ë¡œ ì§€ì—­ë³„ pred ê°’ì„ ì§€ë„ì— í‘œì‹œ.
    - íŒŒë‘(ë‚®ìŒ) ~ ë¹¨ê°•(ë†’ìŒ)
    - Top5 ì§€ì—­ì€ êµµì€ ì› + âš ï¸ í‘œì‹œ
    """
    df_year = df_full[df_full["year"] == selected_year].copy()
    if df_year.empty:
        return None

    df_year["value"] = df_year["pred"]
    df_map = pd.merge(df_year, df_coord, on="region", how="inner")

    df_map = df_map.dropna(subset=["lat", "lon", "value"])
    if df_map.empty:
        return None

    vmin = df_map["value"].min()
    vmax = df_map["value"].max()

    cmap = LinearColormap(
        colors=["#4575b4", "#ffffbf", "#d73027"],  # íŒŒë‘ â†’ ë…¸ë‘ â†’ ë¹¨ê°•
        vmin=vmin,
        vmax=vmax
    )

    center_lat, center_lon = 36.5, 127.8
    m = folium.Map(location=[center_lat, center_lon],
                   zoom_start=7,
                   tiles="cartodbpositron")

    # Top5 (top5_year ê¸°ì¤€)
    df_2050 = df_full[df_full["year"] == top5_year].copy()
    df_2050["value"] = df_2050["pred"]
    top5_regions = (
        df_2050.sort_values("value", ascending=False)["region"]
        .head(5)
        .tolist()
    )

    for _, row in df_map.iterrows():
        color = cmap(row["value"])
        radius = 9
        weight = 1.5
        popup_text = (
            f"{row['region']}<br>"
            f"{selected_year}ë…„ ë©´ì ë‹¹ ë°°ì¶œëŸ‰: {row['value']:.2f} tCOâ‚‚eq/kmÂ²"
        )

        # Top5 ê²½ê³  ìŠ¤íƒ€ì¼
        if row["region"] in top5_regions:
            radius = 13
            weight = 3
            popup_text = "âš ï¸ [Top 5 ë°°ì¶œ ë°€ë„] âš ï¸<br>" + popup_text
            border_color = "black"
        else:
            border_color = color

        CircleMarker(
            location=[row["lat"], row["lon"]],
            radius=radius,
            color=border_color,
            fill=True,
            fill_color=color,
            fill_opacity=0.9,
            weight=weight,
            popup=popup_text,
            tooltip=row["region"],
        ).add_to(m)

    cmap.caption = f"{selected_year}ë…„ ë©´ì ë‹¹ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰ (tCOâ‚‚eq/kmÂ²)"
    cmap.add_to(m)

    return m


# ===========================
# 5. ë©”ì¸ UI
# ===========================
df_hist, df_coord = load_data()
df_full, df_mae = train_and_forecast(df_hist, year_until=2050)

min_year = int(df_full["year"].min())
max_year = int(df_full["year"].max())

tab1, tab2, tab3 = st.tabs([
    "1) ì§€ë„ & ì§€ì—­ë³„ ì¶”ì„¸",
    "2) ë°ì´í„° & ë‹¤ìš´ë¡œë“œ",
    "3) ì˜ˆì¸¡ ì •í™•ë„(MAE) í‰ê°€",
])

# ---------- TAB 1: ì§€ë„ & ì§€ì—­ë³„ ì¶”ì„¸ ----------
with tab1:
    st.subheader("ì „êµ­ ì§€ë„ì—ì„œ í•œëˆˆì— ë³´ëŠ” ë©´ì ë‹¹ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰")

    col_map, col_ctrl = st.columns([3, 1])

    with col_ctrl:
        st.markdown("### ì—°ë„ ì„ íƒ")
        selected_year = st.slider(
            "ì—°ë„",
            min_value=min_year,
            max_value=2050,
            value=2050,
            step=1,
        )
        st.caption(
            "ìŠ¬ë¼ì´ë”ë¥¼ ì›€ì§ì´ë©´ ì—°ë„ë³„ë¡œ ìƒ‰ê¹”ì´ ë³€í•˜ë©´ì„œ\n"
            "ë©´ì ë‹¹ ë°°ì¶œëŸ‰ ë³€í™”ê°€ **ì• ë‹ˆë©”ì´ì…˜ì²˜ëŸ¼** ë³´ì…ë‹ˆë‹¤."
        )

        # ìˆ˜ë™ ì§€ì—­ ì„ íƒë„ ê°€ëŠ¥í•˜ê²Œ
        all_regions = sorted(df_full["region"].unique())
        default_region = all_regions[0] if all_regions else None
        selected_region_manual = st.selectbox(
            "ì§€ì—­ ì§ì ‘ ì„ íƒ",
            all_regions,
            index=0 if default_region else None,
        )

    with col_map:
        m = create_map(df_full, df_coord, selected_year)
        if m is None:
            st.error("ì„ íƒí•œ ì—°ë„ì— ëŒ€í•œ ì§€ë„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            map_state = {}
        else:
            st.caption("ë‹¨ìœ„: tCOâ‚‚eq/kmÂ² (ë©´ì ë‹¹ ì˜¨ì‹¤ê°€ìŠ¤ ë°°ì¶œëŸ‰)")
            map_state = st_folium(m, use_container_width=True, height=600)

    # ì§€ë„ í´ë¦­/ì§€ì—­ ì„ íƒ ì²˜ë¦¬
    if "selected_region" not in st.session_state:
        st.session_state["selected_region"] = selected_region_manual

    clicked_region = None
    if "last_object_clicked_popup" in (map_state or {}):
        popup_html = map_state["last_object_clicked_popup"]
        if popup_html:
            clicked_region = popup_html.split("<br>")[0].replace("âš ï¸ [Top 5 ë°°ì¶œ ë°€ë„] âš ï¸", "").strip()

    if clicked_region:
        st.session_state["selected_region"] = clicked_region
    else:
        st.session_state["selected_region"] = selected_region_manual

    selected_region = st.session_state["selected_region"]

    st.markdown("---")
    st.markdown(f"### ì„ íƒëœ ì§€ì—­: **{selected_region}**")

    df_r_full = df_full[df_full["region"] == selected_region].copy()
    df_r_full = df_r_full.sort_values("year")

    # History / Forecast ë¶„ë¦¬í•´ì„œ ê·¸ë˜í”„ìš© ë°ì´í„° ë§Œë“¤ê¸°
    df_r_plot = pd.DataFrame({
        "year": df_r_full["year"],
        "History / Forecast": np.where(
            df_r_full["kind"] == "history",
            "History",
            "Forecast"
        ),
        "value": df_r_full["pred"],
    })

    # í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë³µ ë°©ì§€ ìœ„í•´ í‰ê· ìœ¼ë¡œ í•œ ë²ˆ ë” ë¬¶ê¸°
    df_r_plot = (
        df_r_plot
        .groupby(["year", "History / Forecast"], as_index=False)["value"]
        .mean()
    )

    df_pivot = df_r_plot.pivot(
        index="year",
        columns="History / Forecast",
        values="value"
    )

    st.line_chart(df_pivot)
    st.caption("â€» ì‹¤ì„ ì€ ì„ í˜•ì¶”ì„¸ + XGBoost ì”ì°¨ë¥¼ ë”í•œ **í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ê°’**ì…ë‹ˆë‹¤. ê³¼ê±° êµ¬ê°„ì—ì„œëŠ” ì‹¤ì œ ê°’ê³¼ ê±°ì˜ ì¼ì¹˜í•©ë‹ˆë‹¤.")

    st.markdown("#### ì¶”ì„¸ ìš”ì•½ & ì •ì±… ì œì•ˆ")
    text = describe_trend_and_solution(df_full, selected_region)
    st.markdown(text)


# ---------- TAB 2: ë°ì´í„° & ë‹¤ìš´ë¡œë“œ ----------
with tab2:
    st.subheader("ì§€ì—­ë³„ ë°ì´í„° & CSV ë‹¤ìš´ë¡œë“œ")

    st.markdown("**â‘  ì „ì²´ ë°ì´í„° (ê³¼ê±° + ì˜ˆì¸¡)**")
    df_export = df_full.copy().rename(columns={
        "region": "Region",
        "year": "Year",
        "actual": "Actual_Emissions_per_Area",
        "pred": "Predicted_Emissions_per_Area",
        "kind": "Type",  # history / forecast
    })

    st.dataframe(df_export.head(200), use_container_width=True)

    csv_bytes = df_export.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        label="ì „ì²´ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ",
        data=csv_bytes,
        file_name="korea_emissions_full_hybrid_forecast.csv",
        mime="text/csv",
    )

    st.markdown("---")
    st.markdown("**â‘¡ 2050ë…„ ì˜ˆì¸¡ê°’ë§Œ ì •ë¦¬í•œ í…Œì´ë¸”**")

    df_2050 = df_full[df_full["year"] == 2050].copy()
    df_2050 = df_2050[["region", "pred"]].rename(columns={
        "region": "Region",
        "pred": "Emissions_per_Area_2050",
    }).sort_values("Emissions_per_Area_2050", ascending=False)

    st.dataframe(df_2050, use_container_width=True)

    csv_2050 = df_2050.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        label="2050ë…„ ì˜ˆì¸¡ ë°ì´í„°ë§Œ CSVë¡œ ë‹¤ìš´ë¡œë“œ",
        data=csv_2050,
        file_name="korea_emissions_2050_only.csv",
        mime="text/csv",
    )


# ---------- TAB 3: ì˜ˆì¸¡ ì •í™•ë„ (MAE) ----------
with tab3:
    st.subheader("XGBoost í•˜ì´ë¸Œë¦¬ë“œ ì˜ˆì¸¡ ì •í™•ë„ í‰ê°€ (MAE ê¸°ì¤€)")

    st.markdown(
        """
        **MAE(Mean Absolute Error, í‰ê·  ì ˆëŒ€ ì˜¤ì°¨)** ëŠ”  
        ëª¨ë¸ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œ ê°’ì˜ ì°¨ì´ë¥¼ ì ˆëŒ€ê°’ìœ¼ë¡œ ë§Œë“¤ì–´ í‰ê· ë‚¸ ì§€í‘œì…ë‹ˆë‹¤.

        - ê°’ì´ **0ì— ê°€ê¹Œìš¸ìˆ˜ë¡** ì˜ˆì¸¡ì´ ì‹¤ì œ ê°’ê³¼ ê±°ì˜ ê°™ë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤.  
        - ë‹¨ìœ„ëŠ” ëª©í‘œ ë³€ìˆ˜ì™€ ë™ì¼í•©ë‹ˆë‹¤. (ì—¬ê¸°ì„œëŠ” `tCOâ‚‚eq/kmÂ²`)

        **í•´ì„ ì˜ˆì‹œ (ëŒ€ëµì ì¸ ê¸°ì¤€)**  
        - MAE **< 5** : ë§¤ìš° ë†’ì€ ì˜ˆì¸¡ ì •í™•ë„  
        - **5 â‰¤ MAE < 15** : ë³´í†µ ìˆ˜ì¤€ì˜ ì˜ˆì¸¡ ì •í™•ë„  
        - MAE **â‰¥ 15** : ì‹¤ì œ ê°’ê³¼ ì°¨ì´ê°€ ê½¤ í° í¸ â†’ ë°ì´í„° ë³´ì™„ ë˜ëŠ” ëª¨ë¸ ê°œì„  í•„ìš”
        """
    )

    st.bar_chart(df_mae.set_index("region")["MAE"])
    st.dataframe(
        df_mae.rename(columns={"region": "Region", "MAE": "MAE (tCOâ‚‚eq/kmÂ²)"}),
        use_container_width=True,
    )

    csv_mae = df_mae.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        label="ì§€ì—­ë³„ MAE ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ",
        data=csv_mae,
        file_name="korea_emissions_mae_by_region.csv",
        mime="text/csv",
    )
